---
title: AI & ML 기초
date: "2019-06-19T01:37:32.169Z"
template: "post"
draft: false
slug: "/tech/AI/AI-ML기초/"
category: "tech"
tags:
  - "AI"
  - "ML"
description: "AI와 ML의 기초를 알아보자"
---

- [머신러닝](#머신러닝)
- [딥러닝](#딥러닝)





## 머신러닝

머신러닝 

- 인공지능의 연구분야 중 하나로, 인간의 학습 능력과 같은 기능을 컴퓨터에서 실현하고자 하는 기술 및 기법
- 순서나 이유를 명확하게 설명하지 못하는 일을 처리하기 위한 방법
- like 고양이나 강아지 구분 / 기분이 안좋아 보인다 / 컴퓨터에게 아이큐테스트 하는 느낌





### 머신러닝의 분류

1. 지도학습

   - Label이 있는 학습 데이터를 이용해서 학습

   1. 분류 (Classification)

      - KNN
      - SVM
      - Decision Tree
      - Logistic 

      |      | 분류(Classification)                          | 회귀(Regression)                                            |
      | ---- | --------------------------------------------- | ----------------------------------------------------------- |
      | 결과 | 학습 데이터의 레이블 중 하나를 예측(discrete) | 연속된 값을 예측<br>얼마까지 오르게 될까? ex)부동산 집값 등 |

   2. 예측

2. 비지도학습

   - Label이 있는 학습 데이터를 이용해서 학습(?)
   - 비슷한 특성을 갖는 데이터로 묶기
   - 현업에서는 아직 사용하기 어렵다.

   1. 군집
      - 레이블이 없다. 
      - 구매자 유형 분류, 의학 임상 실험 환자군 구별
   2. 이상탐지(Anomaly detection)
      - 기존 데이터 패턴과 다른 이상치 검출
   3. 시각화(visualization)
      - 데이터의 특성을 시각화하여 데이터의 패턴 연구
   4. 차원 축소

3. 강화학습

   - 어떤 주어진 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동 중 보상을 최대화 하는행동 혹은 행동 순서를 선택하는 방법
   - ex) 바둑(알파고)

   1. 과적합(overfitting)
      - 학습 데이터에 너무 지나치게 맞추다보면 일반화 성능이 떨어지는 모델 얻게된다.
      - 학습 데이터의 일부를 검증용(validation)으로 사용하거나 교차검증, 데이터셋 늘리기 사용

   



[쉽게 이해하는 딥러닝 영상](https://youtu.be/aF03asAmQbY)

[딥러닝 영상](https://youtu.be/kMGEpIYPCiM)



## 딥러닝(Deep Learning)

### 딥러닝

- 딥러닝?

  - 컴퓨터가 스스로 학습할 수 있게 하기 위해 인공 신경망을 기반으로 하는 기계 학습
  - 인간의 신경망(Neural Network) 이론을 이용한 인공 신경망(ANN, Artificial Neural Network)의 일종으로 계층 구조로 구성되면서 입력층과 출력층 사이에 하나 이상의 은닉층을 가지고 있는 심층 심경망(DNN, Deep Nueral Network)이다.

- 왜 필요한가?

  - 가능한 모든 경우를 찾아도 예외가 발생하게된다.
  - 그러나 이것이 발생하지 않는다.

- 퍼셉트론?

  - 사람의 뇌. 인간의 뉴런과 유사한 동작을 할 수 있게 하기 위해서 들어오는 입력에 따른 가중치를 곱한 값에 어떠한 함수를 계산. 이후 바이어스를 더한 값이 출력값이 된다.
  - y = w1x1 + w2x2 + b

- 작동 원리 예시

  - input 차원에서 직선 혹은 평면을 의미하는 수식

- 다중 퍼셉트론(Multi Layer Perceptron, MLP)

  - 다층 퍼셉트론으로 XOR 연산이 가능

  - 여전히 남은 문제점

    1. 비선형 분류의 어려움

    2. 다층으로 쌓아올린 퍼셉트론의 학습 방법 부재

       => 빙하기 돌입

- Back Propagation

  - 기존의 계산 값을 앞으로 나가는 output 쪽으로만의 계산이 아닌, 다시 뒷단으로 넘어가서 계산했다가 앞으로 나가게 계산하게 하는것을 의미
  - 앞으로 갔다가 뒤로 못오는 경우가 발생할 수 있기 때문에 잘 체크하기 => vanishing gradient solution



